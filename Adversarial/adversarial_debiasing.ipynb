{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78e02443",
   "metadata": {},
   "source": [
    "# Adversarial Debiasing\n",
    "\n",
    "https://github.com/Trusted-AI/AIF360\n",
    "https://arxiv.org/abs/1801.07593\n",
    "\n",
    "\n",
    "\n",
    "@misc{aif360-oct-2018,\n",
    "    title = \"{AI Fairness} 360:  An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias\",\n",
    "    author = {Rachel K. E. Bellamy and Kuntal Dey and Michael Hind and\n",
    "\tSamuel C. Hoffman and Stephanie Houde and Kalapriya Kannan and\n",
    "\tPranay Lohia and Jacquelyn Martino and Sameep Mehta and\n",
    "\tAleksandra Mojsilovic and Seema Nagar and Karthikeyan Natesan Ramamurthy and\n",
    "\tJohn Richards and Diptikalyan Saha and Prasanna Sattigeri and\n",
    "\tMoninder Singh and Kush R. Varshney and Yunfeng Zhang},\n",
    "    month = oct,\n",
    "    year = {2018},\n",
    "    url = {https://arxiv.org/abs/1810.01943}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56e3d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from aif360.datasets import StructuredDataset\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94b7461d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset hatexplain (C:\\Users\\Ahmad\\.cache\\huggingface\\datasets\\hatexplain\\plain_text\\1.0.0\\df474d8d8667d89ef30649bf66e9c856ad8305bef4bc147e8e31cbdf1b8e0249)\n",
      "100%|██████████| 15383/15383 [00:04<00:00, 3162.12ex/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '23107796_gab', 'annotators': {'label': [0, 2, 2], 'annotator_id': [203, 204, 233], 'target': [['Hindu', 'Islam'], ['Hindu', 'Islam'], ['Hindu', 'Islam', 'Other']]}, 'rationales': [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'post_tokens': ['u', 'really', 'think', 'i', 'would', 'not', 'have', 'been', 'raped', 'by', 'feral', 'hindu', 'or', 'muslim', 'back', 'in', 'india', 'or', 'bangladesh', 'and', 'a', 'neo', 'nazi', 'would', 'rape', 'me', 'as', 'well', 'just', 'to', 'see', 'me', 'cry'], 'label': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"hatexplain\", split=\"train\")\n",
    "train_dataset = train_dataset.map(lambda e: {\"label\" : int(np.median(e[\"annotators\"][\"label\"]))})\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4520c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset hatexplain (C:\\Users\\Ahmad\\.cache\\huggingface\\datasets\\hatexplain\\plain_text\\1.0.0\\df474d8d8667d89ef30649bf66e9c856ad8305bef4bc147e8e31cbdf1b8e0249)\n",
      "Reusing dataset hatexplain (C:\\Users\\Ahmad\\.cache\\huggingface\\datasets\\hatexplain\\plain_text\\1.0.0\\df474d8d8667d89ef30649bf66e9c856ad8305bef4bc147e8e31cbdf1b8e0249)\n",
      "Reusing dataset hatexplain (C:\\Users\\Ahmad\\.cache\\huggingface\\datasets\\hatexplain\\plain_text\\1.0.0\\df474d8d8667d89ef30649bf66e9c856ad8305bef4bc147e8e31cbdf1b8e0249)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Homosexual', 'Indian', 'Refugee', 'Hispanic', 'Asexual', 'Islam', 'African', 'Hindu', 'Disability', 'Other', 'Men', 'Asian', 'Christian', 'Minority', 'Indigenous', 'Bisexual', 'Heterosexual', 'Buddhism', 'None', 'Arab', 'Nonreligious', 'Caucasian', 'Economic', 'Women', 'Jewish'}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"hatexplain\", split=\"train\")\n",
    "test_dataset = load_dataset(\"hatexplain\", split=\"test\")\n",
    "val_dataset = load_dataset(\"hatexplain\", split=\"validation\")\n",
    "\n",
    "class_names = [\"hate speech\", \"normal\", \"offensive\"]\n",
    "targets = []\n",
    "\n",
    "protected_groups = {'Homosexual', 'Indian', 'Refugee', 'Hispanic', 'Asexual', 'Islam', 'African', 'Hindu', 'Disability', 'Other', 'Asian', 'Christian', 'Minority', 'Indigenous', 'Bisexual', 'Heterosexual', 'Buddhism', 'None', 'Arab', 'Nonreligious', 'Caucasian', 'Economic', 'Women', 'Jewish'}\n",
    "\n",
    "#train_tokens = tokenizer(train_dataset['post_tokens'], padding=True,is_split_into_words=True, return_tensors=\"pt\")\n",
    "#test_tokens = tokenizer(test_dataset['post_tokens'], padding=True,is_split_into_words=True, return_tensors=\"pt\")\n",
    "#val_tokens = tokenizer(val_dataset['post_tokens'], padding=True,is_split_into_words=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
