{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HateXplain\n",
    "\n",
    "https://huggingface.co/Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two\n",
    "\n",
    "\n",
    "The model is used for classifying a text as Abusive (Hatespeech and Offensive) or Normal. The model is trained using data from Gab and Twitter and Human Rationales were included as part of the training data to boost the performance. The model also has a rationale predictor head that can predict the rationales given an abusive sentence.\n",
    "\n",
    "The dataset and models are available here: https://github.com/punyajoy/HateXplain\n",
    "\n",
    "\n",
    "Binny Mathew, Punyajoy Saha, Seid Muhie Yimam, Chris Biemann, Pawan Goyal, and Animesh Mukherjee \"[HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection)\". Accepted at AAAI 2021.\n",
    "\n",
    "\n",
    "@article{mathew2020hatexplain,\n",
    "  title={HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection},\n",
    "  author={Mathew, Binny and Saha, Punyajoy and Yimam, Seid Muhie and Biemann, Chris and Goyal, Pawan and Mukherjee, Animesh},\n",
    "  journal={arXiv preprint arXiv:2012.10289},\n",
    "  year={2020}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "### from models.py\n",
    "from models import *\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "seed = 42\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Hate-speech-CNERG/bert-base-uncased-hatexplain\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"Hate-speech-CNERG/bert-base-uncased-hatexplain\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset hatexplain (C:\\Users\\Ahmad\\.cache\\huggingface\\datasets\\hatexplain\\plain_text\\1.0.0\\df474d8d8667d89ef30649bf66e9c856ad8305bef4bc147e8e31cbdf1b8e0249)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"hatexplain\", split=\"validation\")\n",
    "\n",
    "class_names = [\"hate speech\", \"normal\", \"offensive\"]\n",
    "#dataset = dataset.map(lambda e: tokenizer(e['post_tokens'], truncation=True, padding='longest', is_split_into_words=True), batched=True)\n",
    "\n",
    "data_tokens = tokenizer(dataset['post_tokens'], padding=True,is_split_into_words=True, return_tensors=\"pt\")\n",
    "\n",
    "#for i in range(len(dataset)):\n",
    "#    print(f\"data: {' '.join(dataset[i]['post_tokens'])} \\n\\t label: {dataset[i]['annotators']['label']}\\n\")\n",
    "\n",
    "\n",
    "#dataloader = DataLoader(data_tokens, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "input_tensor = []\n",
    "attention_mask_tensor = []\n",
    "for i in range(0,len(data_tokens.input_ids), batch_size):\n",
    "    input_tensor += [data_tokens.input_ids[i:i+batch_size]]\n",
    "    attention_mask_tensor += [data_tokens.attention_mask[i:i+batch_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n",
      "<class 'str'>\n",
      "attentions\n"
     ]
    }
   ],
   "source": [
    "logits_list = []\n",
    "for i in range(len(input_tensor)):\n",
    "    with torch.no_grad():\n",
    "        inp = input_tensor[i].to(device)\n",
    "        attention = attention_mask_tensor[i].to(device)\n",
    "        prediction_logits, what = model(input_ids=inp,attention_mask=attention)\n",
    "        print(type(prediction_logits))\n",
    "        print(what)\n",
    "\n",
    "        logits_list.append(prediction_logits)\n",
    "        \n",
    "        inp.detach()\n",
    "        attention.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['logits', 'logits', 'logits', 'logits', 'logits', 'logits', 'logits', 'logits', 'logits', 'logits']\n",
      "logits\n"
     ]
    }
   ],
   "source": [
    "print(logits_list[:10])\n",
    "print(prediction_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38852/874437726.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpredicitons\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpredicitons\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'annotators'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not str"
     ]
    }
   ],
   "source": [
    "predicitons = []\n",
    "for i in range(len(logits_list)):\n",
    "    predicitons += [(torch.argmax(logits_list[i], dim=1).item(), dataset[i]['annotators']['label'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicitons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"dataset size: {len(data)}\")\n",
    "for i in range(len(data)):\n",
    "    print(f\"data: {' '.join(dataset[i]['post_tokens'])} \\n\\tpredictiton: {predicitons[i]} {class_names[predicitons[i]]} \\n\\tlable: {dataset[i]['annotators']['label']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af2dc65967692050cab8e66feb265a08b4036dabf5bf167c8e1e4da3fe6ea63e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
