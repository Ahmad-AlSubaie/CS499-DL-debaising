{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb4espuLKJiA"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Hub Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "jM3hCI1UUzar"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ6SNYq_tVVC"
      },
      "source": [
        "# Classify text with BERT\n",
        "\n",
        "This fine-tuned BERT model is trained to classify tweets into 3 labels, 0 = \"hate speech\", 1 = \"offensive language\", 2 = \"neither\". \n",
        "\n",
        "Trained on https://github.com/t-davidson/hate-speech-and-offensive-language\n",
        "\n",
        "testing dataset from https://github.com/hate-alert/HateXplain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCjmX4zTCkRK"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-YbjCkzw0yU"
      },
      "outputs": [],
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "#!pip install -q -U \"tensorflow-text==2.8.*\"\n",
        "#!pip install -q tf-models-official==2.7.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading in packages and initilizing constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_XgTpm9ZxoN9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "tf.get_logger().setLevel('ERROR')\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "test_train_ratio = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6MugfEgDRpY"
      },
      "source": [
        "## Loading in datasets\n",
        "\n",
        "hate_data holds the train and validaiton dataset from the hatespeech dataset\n",
        "\n",
        "train_ds, val_ds, and test_ds are batched and shuffled tf.data.Dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"hatexplain\", split=\"validation\")\n",
        "\n",
        "class_names = [\"hate speech\", \"normal\", \"offensive\"]\n",
        "\n",
        "data_tokens = tokenizer(dataset['post_tokens'], padding=True,is_split_into_words=True, return_tensors=\"tf\")\n",
        "\n",
        "\n",
        "input_tensor = []\n",
        "attention_mask_tensor = []\n",
        "for i in range(0,len(data_tokens.input_ids), batch_size):\n",
        "    input_tensor += [data_tokens.input_ids[i:i+batch_size]]\n",
        "    attention_mask_tensor += [data_tokens.attention_mask[i:i+batch_size]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKnLPSEmtp9i"
      },
      "source": [
        "## Loading the BERT model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tXxYpK8ixL34"
      },
      "outputs": [],
      "source": [
        "ataset_name = 'hate_speech'\n",
        "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
        "\n",
        "reloaded_model = tf.saved_model.load(saved_model_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "classify_text_with_bert.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
